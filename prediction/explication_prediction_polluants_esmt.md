# ğŸ“˜ README â€“ ModÃ¨le de PrÃ©diction de la QualitÃ© de lâ€™Air (J+1)

Ce projet permet de **prÃ©dire la qualitÃ© de lâ€™air du lendemain (J+1)** Ã  partir des donnÃ©es des jours prÃ©cÃ©dents.
Le modÃ¨le utilisÃ© est basÃ© sur **XGBoost**, capable de gÃ©rer plusieurs variables cibles (polluants, tempÃ©rature, humiditÃ©, etc.) simultanÃ©ment.

---

## ğŸ”§ Ã‰tapes principales du code

### 1. Imports

Le code utilise :

* **Pandas / NumPy** : manipulation de donnÃ©es.
* **Scikit-learn** : normalisation, mÃ©triques, GridSearchCV.
* **XGBoost** : algorithme principal de rÃ©gression.
* **Joblib** : sauvegarde/chargement des modÃ¨les et paramÃ¨tres.

---

### 2. Transformation en problÃ¨me supervisÃ©

La fonction `create_supervised(df, n_lags)` transforme la sÃ©rie temporelle en problÃ¨me de prÃ©diction supervisÃ©e.

ğŸ‘‰ Exemple : si `n_lags = 3`, on utilise les 3 derniers jours pour prÃ©dire le jour courant.

* Les colonnes deviennent `variable(t-3)`, `variable(t-2)`, `variable(t-1)` pour les features.
* Les colonnes du jour courant `variable(t)` servent de **cibles**.

---

### 3. PrÃ©paration des donnÃ©es

* Suppression des colonnes inutiles (`Location ID`, `Sensor ID`, etc.).
* Conversion des dates en format datetime et tri par ordre chronologique.
* Indexation du DataFrame par la date.
* Application de `create_supervised` pour gÃ©nÃ©rer les donnÃ©es exploitables par le modÃ¨le.

---

### 4. DÃ©coupage Train/Test

* On sÃ©pare 80% des donnÃ©es pour lâ€™entraÃ®nement, 20% pour le test.
* `X_train` = features (jours passÃ©s).
* `y_train` = cibles (valeurs des polluants du jour courant).
* MÃªme dÃ©coupage pour le test.

---

### 5. Normalisation

On applique un **StandardScaler** (moyenne = 0, Ã©cart-type = 1) :

* `scaler_X` pour les variables explicatives.
* `scaler_y` pour les variables cibles.

âš ï¸ Important : les scalers sont sauvegardÃ©s pour rÃ©utilisation en production.

---

### 6. DÃ©finition du modÃ¨le

* Base : `XGBRegressor` (XGBoost en rÃ©gression).
* Enveloppe : `MultiOutputRegressor` â†’ permet de prÃ©dire **plusieurs variables Ã  la fois**.
* Une grille dâ€™hyperparamÃ¨tres (`n_estimators`, `learning_rate`, `max_depth`, etc.) est dÃ©finie pour optimiser le modÃ¨le.

---

### 7. Optimisation par Grid Search

* On utilise `GridSearchCV` avec validation croisÃ©e (`cv=5`) pour tester toutes les combinaisons dâ€™hyperparamÃ¨tres.
* La mÃ©trique utilisÃ©e est le **RÂ²** (ou `neg_mean_squared_error` si besoin).
* Le meilleur ensemble dâ€™hyperparamÃ¨tres est sÃ©lectionnÃ©.

---

### 8. EntraÃ®nement final et Ã©valuation

* Le modÃ¨le est rÃ©entraÃ®nÃ© sur tout le jeu dâ€™entraÃ®nement avec les meilleurs paramÃ¨tres.
* On Ã©value sur le jeu de test avec :

  * **RMSE** (Root Mean Squared Error) : erreur quadratique moyenne.
  * **MAE** (Mean Absolute Error) : erreur absolue moyenne.
  * **RÂ²** (coefficient de dÃ©termination).

ğŸ‘‰ Ces mÃ©triques permettent de comparer le modÃ¨le avec une baseline (par ex. persistance = Â« demain = aujourdâ€™hui Â»).

---

### 9. Sauvegarde des artefacts

Les objets suivants sont sauvegardÃ©s avec `joblib` :

* `xgboost_multioutput.pkl` â†’ le modÃ¨le entraÃ®nÃ©.
* `scaler_X.pkl` et `scaler_y.pkl` â†’ les normalisations utilisÃ©es.
* `target_columns.pkl` â†’ les colonnes cibles (polluants, mÃ©tÃ©o, etc.).
* `n_lags.pkl` â†’ nombre de jours utilisÃ©s pour prÃ©dire J+1.

ğŸ‘‰ Ces fichiers permettent de recharger le modÃ¨le directement en production.

---

### 10. Fonction de prÃ©diction J+1

La fonction `predict_j_plus_1(last_days_df)` :

1. Charge le modÃ¨le et les paramÃ¨tres sauvegardÃ©s.
2. VÃ©rifie que `last_days_df` contient **exactement `n_lags` jours** et toutes les colonnes nÃ©cessaires.
3. Construit les features (`t-1`, `t-2`, â€¦).
4. Applique les scalers et prÃ©dit.
5. Retourne un DataFrame avec les valeurs prÃ©dites pour **le lendemain**.

ğŸ‘‰ Exemple de sortie :

```
            PM2.5 (Âµg/mÂ³) corrected   CO2 (ppm) corrected   Humidity (%) corrected
2025-08-21                 12.5                    405.2                    71.8
```

---

### 11. Exemple dâ€™utilisation

```python
dernier_jours = df.tail(n_lags)   # Les derniers jours connus
print("ğŸ”® PrÃ©diction J+1 :")
print(predict_j_plus_1(dernier_jours))
```

---

## ğŸš€ En rÃ©sumÃ©

1. On prÃ©pare les donnÃ©es (suppression colonnes, indexation date).
2. On crÃ©e un problÃ¨me supervisÃ© avec `n_lags` jours en entrÃ©e.
3. On normalise les donnÃ©es.
4. On entraÃ®ne un modÃ¨le XGBoost multi-sorties optimisÃ© par GridSearch.
5. On Ã©value la performance.
6. On sauvegarde le modÃ¨le et ses paramÃ¨tres.
7. On fournit une fonction clÃ© en main pour prÃ©dire J+1.

---

## ğŸ’¡ AmÃ©liorations possibles

* Tester diffÃ©rents `n_lags` (ex. 3, 5, 7).
* Ajouter des features mÃ©tÃ©o (tempÃ©rature max/min, humiditÃ©, vent) - on pense a openweather .
* EntraÃ®ner un modÃ¨le par polluant plutÃ´t quâ€™un multi-sortie.
* Comparer avec dâ€™autres algorithmes (Ridge, Lasso, RandomForest).
