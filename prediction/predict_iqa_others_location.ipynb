{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP10nf1f6MBv1hpN653g4Ab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-houngbo/respire/blob/main/prediction/predict_iqa_others_location.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "k-1C3rifsZjW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "import gdown\n",
        "\n",
        "# ID des Datasets et noms des outputs\n",
        "file_ids = [\"1BZazndHP417b_nUGeSxmB-wdaYDb6Ngk\",\"1YXLAh-6muUdr_OozqJKX-NKtqQrD6Oh3\",\"1T_k88fw5VGXLElxMLnfZZjVYW-10tJsU\",\"14icTE7xhjxpWL_yetgMY0e0nGAlAV3Zz\",\"1RwCELDqcmiayG-hGTf-8G2iNB9Pmsbrd\"]\n",
        "outputs = [\"iqa-164928.csv\",\"iqa-151726.csv\",\"iqa-90106.csv\",\"iqa-90104.csv\",\"iqa-89441.csv\"]\n",
        "\n",
        "\n",
        "for i,file_id in enumerate(file_ids):\n",
        "  url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "  output = outputs[i]\n",
        "  gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3v0qQjXsoHF",
        "outputId": "cac1814c-6bf2-4d7b-88a2-1fb1e860b590"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BZazndHP417b_nUGeSxmB-wdaYDb6Ngk\n",
            "To: /content/iqa-164928.csv\n",
            "100%|██████████| 427/427 [00:00<00:00, 987kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YXLAh-6muUdr_OozqJKX-NKtqQrD6Oh3\n",
            "To: /content/iqa-151726.csv\n",
            "100%|██████████| 1.86k/1.86k [00:00<00:00, 4.44MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1T_k88fw5VGXLElxMLnfZZjVYW-10tJsU\n",
            "To: /content/iqa-90106.csv\n",
            "100%|██████████| 1.39k/1.39k [00:00<00:00, 3.43MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14icTE7xhjxpWL_yetgMY0e0nGAlAV3Zz\n",
            "To: /content/iqa-90104.csv\n",
            "100%|██████████| 1.86k/1.86k [00:00<00:00, 4.19MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RwCELDqcmiayG-hGTf-8G2iNB9Pmsbrd\n",
            "To: /content/iqa-89441.csv\n",
            "100%|██████████| 750/750 [00:00<00:00, 2.70MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "listt = [\"164928\",\"151726\",\"90106\",\"90104\",\"89441\"]\n",
        "\n",
        "# df_164928 = pd.read_csv(\"iqa-164928.csv\")\n",
        "df_151726 = pd.read_csv(\"iqa-151726.csv\")\n",
        "df_90106 = pd.read_csv(\"iqa-90106.csv\")\n",
        "df_90104 = pd.read_csv(\"iqa-90104.csv\")\n",
        "df_89441 = pd.read_csv(\"iqa-89441.csv\")\n"
      ],
      "metadata": {
        "id": "e6c3PWP5sorq"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {id_: pd.read_csv(f\"iqa-{id_}.csv\") for id_ in listt}"
      ],
      "metadata": {
        "id": "u13cIp_Kw642"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##151726"
      ],
      "metadata": {
        "id": "ROQnYnnBMCH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_151726.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_lIqSXm-mCM",
        "outputId": "65ed1d24-3a69-49a0-b909-ce45a977dca3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 98 entries, 0 to 97\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    98 non-null     object \n",
            " 1   iqa     98 non-null     float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 1.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Linear Regression — time-series friendly (lags, TSCV, eval, save, multi-step forecast)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# === 1) Données ===\n",
        "df = df_151726.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').set_index('date').asfreq('D')\n",
        "df['iqa'] = df['iqa'].interpolate()\n",
        "\n",
        "\n",
        "# === 2) Lags ===\n",
        "def create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = data.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        out[f'lag_{lag}'] = out['iqa'].shift(lag)\n",
        "    return out\n",
        "\n",
        "n_lags = 7\n",
        "df_lags = create_lags(df[['iqa']], n_lags).dropna()\n",
        "\n",
        "# === 3) Split train/test ===\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "train = df_lags.iloc[:train_size].copy()\n",
        "test  = df_lags.iloc[train_size:].copy()\n",
        "\n",
        "X_train, y_train = train.drop(columns=['iqa']), train['iqa']\n",
        "X_test,  y_test  = test.drop(columns=['iqa']),  test['iqa']\n",
        "\n",
        "# === 4) CV temporelle (RMSE par fold)\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression(n_jobs=None)  # n_jobs not supported; kept for symmetry\n",
        ")\n",
        "\n",
        "def cv_rmse(model, X, y, splitter):\n",
        "    rmses = []\n",
        "    for tr_idx, val_idx in splitter.split(X):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        est = clone(model)\n",
        "        est.fit(X_tr, y_tr)\n",
        "        y_hat = est.predict(X_val)\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\n",
        "    return np.array(rmses)\n",
        "\n",
        "cv_rmse_per_fold = cv_rmse(base_lr, X_train, y_train, tscv)\n",
        "print(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\n",
        "print(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\n",
        "\n",
        "# === 5) Entraînement final (val interne 20% — pas d’early stopping pour LR)\n",
        "val_cut = max(int(len(X_train) * 0.8), 1)\n",
        "X_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\n",
        "X_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\n",
        "\n",
        "final_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression()\n",
        ")\n",
        "final_lr.fit(X_tr, y_tr)\n",
        "\n",
        "# === 6) Évaluation test ===\n",
        "y_pred = final_lr.predict(X_test)\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"🔎 Évaluation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# === 7) Sauvegarde ===\n",
        "joblib.dump(final_lr, f\"linreg_iqa_best_{151726}.pkl\")\n",
        "print(f\"✅ Modèle sauvegardé : linreg_iqa_best_{151726}.pkl\")\n",
        "\n",
        "# === 8) Prédiction J+1 ===\n",
        "last_feats = df_lags.drop(columns=['iqa']).iloc[-1:].copy()\n",
        "pred_next_day = float(final_lr.predict(last_feats)[0])\n",
        "print(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\n",
        "\n",
        "# === 9) Prédictions J+1 → J+5 (auto-régression) ===\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "lag_cols = [f'lag_{k}' for k in range(1, n_lags + 1)]\n",
        "step_feats = last_feats.copy()\n",
        "\n",
        "for _ in range(n_days):\n",
        "    y_hat = float(final_lr.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\n",
        "    shifted[0] = y_hat\n",
        "    step_feats[lag_cols] = shifted\n",
        "\n",
        "print(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2AlM94aFKrw",
        "outputId": "8eb86e6a-b8b7-45e9-916f-8679a66be13c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CV RMSE per fold : [6.8969 4.0716 2.3245 4.1009 2.5387]\n",
            "📊 CV RMSE mean     : 3.9865\n",
            "🔎 Évaluation sur test :\n",
            "   RMSE = 5.4077\n",
            "   MAE  = 4.0387\n",
            "   R2   = -0.0789\n",
            "✅ Modèle sauvegardé : linreg_iqa_best_151726.pkl\n",
            "📅 Prédiction J+1 : 124.58\n",
            "📅 Prédictions J+1 à J+5 : [124.58, 119.71, 121.94, 120.99, 120.59]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##90106"
      ],
      "metadata": {
        "id": "c2rNaA0SQqWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_90106.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHOIL4qhBluq",
        "outputId": "468adbb6-5d7c-4580-f88d-2f6b89885fcf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 86 entries, 0 to 85\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    86 non-null     object \n",
            " 1   iqa     44 non-null     float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 1.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_90106 = df_90106.dropna()"
      ],
      "metadata": {
        "id": "waP2nw3sDvTH"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Linear Regression — time-series friendly (lags, TSCV, eval, save, multi-step forecast)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# === 1) Données ===\n",
        "df = df_90106.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').set_index('date').asfreq('D')\n",
        "df['iqa'] = df['iqa'].interpolate()\n",
        "\n",
        "\n",
        "# === 2) Lags ===\n",
        "def create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = data.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        out[f'lag_{lag}'] = out['iqa'].shift(lag)\n",
        "    return out\n",
        "\n",
        "n_lags = 7\n",
        "df_lags = create_lags(df[['iqa']], n_lags).dropna()\n",
        "\n",
        "# === 3) Split train/test ===\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "train = df_lags.iloc[:train_size].copy()\n",
        "test  = df_lags.iloc[train_size:].copy()\n",
        "\n",
        "X_train, y_train = train.drop(columns=['iqa']), train['iqa']\n",
        "X_test,  y_test  = test.drop(columns=['iqa']),  test['iqa']\n",
        "\n",
        "# === 4) CV temporelle (RMSE par fold)\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression(n_jobs=None)  # n_jobs not supported; kept for symmetry\n",
        ")\n",
        "\n",
        "def cv_rmse(model, X, y, splitter):\n",
        "    rmses = []\n",
        "    for tr_idx, val_idx in splitter.split(X):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        est = clone(model)\n",
        "        est.fit(X_tr, y_tr)\n",
        "        y_hat = est.predict(X_val)\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\n",
        "    return np.array(rmses)\n",
        "\n",
        "cv_rmse_per_fold = cv_rmse(base_lr, X_train, y_train, tscv)\n",
        "print(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\n",
        "print(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\n",
        "\n",
        "# === 5) Entraînement final (val interne 20% — pas d’early stopping pour LR)\n",
        "val_cut = max(int(len(X_train) * 0.8), 1)\n",
        "X_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\n",
        "X_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\n",
        "\n",
        "final_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression()\n",
        ")\n",
        "final_lr.fit(X_tr, y_tr)\n",
        "\n",
        "# === 6) Évaluation test ===\n",
        "y_pred = final_lr.predict(X_test)\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"🔎 Évaluation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# === 7) Sauvegarde ===\n",
        "joblib.dump(final_lr, f\"linreg_iqa_best_{90106}.pkl\")\n",
        "print(f\"✅ Modèle sauvegardé : linreg_iqa_best_{90106}.pkl\")\n",
        "\n",
        "# === 8) Prédiction J+1 ===\n",
        "last_feats = df_lags.drop(columns=['iqa']).iloc[-1:].copy()\n",
        "pred_next_day = float(final_lr.predict(last_feats)[0])\n",
        "print(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\n",
        "\n",
        "# === 9) Prédictions J+1 → J+5 (auto-régression) ===\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "lag_cols = [f'lag_{k}' for k in range(1, n_lags + 1)]\n",
        "step_feats = last_feats.copy()\n",
        "\n",
        "for _ in range(n_days):\n",
        "    y_hat = float(final_lr.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\n",
        "    shifted[0] = y_hat\n",
        "    step_feats[lag_cols] = shifted\n",
        "\n",
        "print(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gn5VP6aPMD5",
        "outputId": "16125fb8-8ada-4900-f767-de5db5b57ad5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CV RMSE per fold : [52.2576 75.5688 49.2218 18.0473  9.8582]\n",
            "📊 CV RMSE mean     : 40.9907\n",
            "🔎 Évaluation sur test :\n",
            "   RMSE = 28.9748\n",
            "   MAE  = 15.2997\n",
            "   R2   = 0.1135\n",
            "✅ Modèle sauvegardé : linreg_iqa_best_90106.pkl\n",
            "📅 Prédiction J+1 : 142.05\n",
            "📅 Prédictions J+1 à J+5 : [142.05, 150.78, 158.77, 167.87, 176.28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 90104"
      ],
      "metadata": {
        "id": "9VWKTi2-Qq9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_90104.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW5nBytJB0iU",
        "outputId": "788fd08d-5b66-4625-b6d4-c75b5146dd5d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 98 entries, 0 to 97\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    98 non-null     object \n",
            " 1   iqa     98 non-null     float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 1.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Linear Regression — time-series friendly (lags, TSCV, eval, save, multi-step forecast)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# === 1) Données ===\n",
        "df = df_90104.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').set_index('date').asfreq('D')\n",
        "df['iqa'] = df['iqa'].interpolate()\n",
        "\n",
        "\n",
        "# === 2) Lags ===\n",
        "def create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = data.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        out[f'lag_{lag}'] = out['iqa'].shift(lag)\n",
        "    return out\n",
        "\n",
        "n_lags = 7\n",
        "df_lags = create_lags(df[['iqa']], n_lags).dropna()\n",
        "\n",
        "# === 3) Split train/test ===\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "train = df_lags.iloc[:train_size].copy()\n",
        "test  = df_lags.iloc[train_size:].copy()\n",
        "\n",
        "X_train, y_train = train.drop(columns=['iqa']), train['iqa']\n",
        "X_test,  y_test  = test.drop(columns=['iqa']),  test['iqa']\n",
        "\n",
        "# === 4) CV temporelle (RMSE par fold)\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression(n_jobs=None)  # n_jobs not supported; kept for symmetry\n",
        ")\n",
        "\n",
        "def cv_rmse(model, X, y, splitter):\n",
        "    rmses = []\n",
        "    for tr_idx, val_idx in splitter.split(X):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        est = clone(model)\n",
        "        est.fit(X_tr, y_tr)\n",
        "        y_hat = est.predict(X_val)\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\n",
        "    return np.array(rmses)\n",
        "\n",
        "cv_rmse_per_fold = cv_rmse(base_lr, X_train, y_train, tscv)\n",
        "print(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\n",
        "print(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\n",
        "\n",
        "# === 5) Entraînement final (val interne 20% — pas d’early stopping pour LR)\n",
        "val_cut = max(int(len(X_train) * 0.8), 1)\n",
        "X_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\n",
        "X_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\n",
        "\n",
        "final_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression()\n",
        ")\n",
        "final_lr.fit(X_tr, y_tr)\n",
        "\n",
        "# === 6) Évaluation test ===\n",
        "y_pred = final_lr.predict(X_test)\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"🔎 Évaluation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# === 7) Sauvegarde ===\n",
        "joblib.dump(final_lr, f\"linreg_iqa_best_{90104}.pkl\")\n",
        "print(f\"✅ Modèle sauvegardé : linreg_iqa_best_{90104}.pkl\")\n",
        "\n",
        "# === 8) Prédiction J+1 ===\n",
        "last_feats = df_lags.drop(columns=['iqa']).iloc[-1:].copy()\n",
        "pred_next_day = float(final_lr.predict(last_feats)[0])\n",
        "print(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\n",
        "\n",
        "# === 9) Prédictions J+1 → J+5 (auto-régression) ===\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "lag_cols = [f'lag_{k}' for k in range(1, n_lags + 1)]\n",
        "step_feats = last_feats.copy()\n",
        "\n",
        "for _ in range(n_days):\n",
        "    y_hat = float(final_lr.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\n",
        "    shifted[0] = y_hat\n",
        "    step_feats[lag_cols] = shifted\n",
        "\n",
        "print(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA87AaDYQrmC",
        "outputId": "bcd68e98-d0f8-4248-cae4-54517d8f6723"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CV RMSE per fold : [11.5149  6.2823  3.3327  4.8162  4.9307]\n",
            "📊 CV RMSE mean     : 6.1754\n",
            "🔎 Évaluation sur test :\n",
            "   RMSE = 4.7308\n",
            "   MAE  = 3.9633\n",
            "   R2   = 0.4102\n",
            "✅ Modèle sauvegardé : linreg_iqa_best_90104.pkl\n",
            "📅 Prédiction J+1 : 128.13\n",
            "📅 Prédictions J+1 à J+5 : [128.13, 134.02, 134.34, 132.5, 129.27]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 89441"
      ],
      "metadata": {
        "id": "aZ-nCf21Qr-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_89441.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGjSAAXOCSbk",
        "outputId": "65481c38-4629-43c2-83e0-0d30b38fb077"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39 entries, 0 to 38\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   date    39 non-null     object \n",
            " 1   iqa     39 non-null     float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 756.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Linear Regression — time-series friendly (lags, TSCV, eval, save, multi-step forecast)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# === 1) Données ===\n",
        "df = df_89441.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').set_index('date').asfreq('D')\n",
        "df['iqa'] = df['iqa'].interpolate()\n",
        "\n",
        "\n",
        "# === 2) Lags ===\n",
        "def create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = data.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        out[f'lag_{lag}'] = out['iqa'].shift(lag)\n",
        "    return out\n",
        "\n",
        "n_lags = 7\n",
        "df_lags = create_lags(df[['iqa']], n_lags).dropna()\n",
        "\n",
        "# === 3) Split train/test ===\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "train = df_lags.iloc[:train_size].copy()\n",
        "test  = df_lags.iloc[train_size:].copy()\n",
        "\n",
        "X_train, y_train = train.drop(columns=['iqa']), train['iqa']\n",
        "X_test,  y_test  = test.drop(columns=['iqa']),  test['iqa']\n",
        "\n",
        "# === 4) CV temporelle (RMSE par fold)\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression(n_jobs=None)  # n_jobs not supported; kept for symmetry\n",
        ")\n",
        "\n",
        "def cv_rmse(model, X, y, splitter):\n",
        "    rmses = []\n",
        "    for tr_idx, val_idx in splitter.split(X):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        est = clone(model)\n",
        "        est.fit(X_tr, y_tr)\n",
        "        y_hat = est.predict(X_val)\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\n",
        "    return np.array(rmses)\n",
        "\n",
        "cv_rmse_per_fold = cv_rmse(base_lr, X_train, y_train, tscv)\n",
        "print(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\n",
        "print(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\n",
        "\n",
        "# === 5) Entraînement final (val interne 20% — pas d’early stopping pour LR)\n",
        "val_cut = max(int(len(X_train) * 0.8), 1)\n",
        "X_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\n",
        "X_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\n",
        "\n",
        "final_lr = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    LinearRegression()\n",
        ")\n",
        "final_lr.fit(X_tr, y_tr)\n",
        "\n",
        "# === 6) Évaluation test ===\n",
        "y_pred = final_lr.predict(X_test)\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"🔎 Évaluation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# === 7) Sauvegarde ===\n",
        "joblib.dump(final_lr, f\"linreg_iqa_best_{89441}.pkl\")\n",
        "print(f\"✅ Modèle sauvegardé : linreg_iqa_best_{89441}.pkl\")\n",
        "\n",
        "# === 8) Prédiction J+1 ===\n",
        "last_feats = df_lags.drop(columns=['iqa']).iloc[-1:].copy()\n",
        "pred_next_day = float(final_lr.predict(last_feats)[0])\n",
        "print(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\n",
        "\n",
        "# === 9) Prédictions J+1 → J+5 (auto-régression) ===\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "lag_cols = [f'lag_{k}' for k in range(1, n_lags + 1)]\n",
        "step_feats = last_feats.copy()\n",
        "\n",
        "for _ in range(n_days):\n",
        "    y_hat = float(final_lr.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\n",
        "    shifted[0] = y_hat\n",
        "    step_feats[lag_cols] = shifted\n",
        "\n",
        "print(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQCq_5HqQs0Y",
        "outputId": "d5be925a-1293-4235-e514-36baca541183"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 CV RMSE per fold : [ 6.0292  3.8879 10.2312  6.2934  4.8017]\n",
            "📊 CV RMSE mean     : 6.2487\n",
            "🔎 Évaluation sur test :\n",
            "   RMSE = 6.1670\n",
            "   MAE  = 4.2326\n",
            "   R2   = -0.2270\n",
            "✅ Modèle sauvegardé : linreg_iqa_best_89441.pkl\n",
            "📅 Prédiction J+1 : 114.38\n",
            "📅 Prédictions J+1 à J+5 : [114.38, 118.39, 120.25, 123.09, 120.46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UebWJaCrCbuw"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XwMrdzc1HJP5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoLIHXm5HJMU"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NmOFkBwwHJJQ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAZZp_EoHJFB"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QryCS6TJHJB7"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amlmY_ABHINl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UjOUERJHHIJ_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GKPymBTHIHG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# CECI EST UN TEST D'UTILISATION DU MODELE XGB\n",
        "\n",
        "\n",
        "# XGBoost — time-series friendly (lags, TSCV, eval with early stopping, save, multi-step forecast)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# === 1) Données ===\n",
        "df = df_151726.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').set_index('date').asfreq('D')\n",
        "df['iqa'] = df['iqa'].interpolate()\n",
        "\n",
        "# === 2) Lags ===\n",
        "def create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\n",
        "    out = data.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        out[f'lag_{lag}'] = out['iqa'].shift(lag)\n",
        "    return out\n",
        "\n",
        "n_lags = 7\n",
        "df_lags = create_lags(df[['iqa']], n_lags).dropna()\n",
        "\n",
        "# === 3) Split train/test ===\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "train = df_lags.iloc[:train_size].copy()\n",
        "test  = df_lags.iloc[train_size:].copy()\n",
        "\n",
        "X_train, y_train = train.drop(columns=['iqa']), train['iqa']\n",
        "X_test,  y_test  = test.drop(columns=['iqa']),  test['iqa']\n",
        "\n",
        "# === 4) CV temporelle (RMSE par fold) — avec early stopping\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_xgb = XGBRegressor(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=3,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    tree_method=\"hist\",\n",
        "    objective=\"reg:squarederror\",\n",
        "    eval_metric=\"rmse\",\n",
        ")\n",
        "\n",
        "def cv_rmse(model, X, y, splitter):\n",
        "    rmses = []\n",
        "    for tr_idx, val_idx in splitter.split(X):\n",
        "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "        est = clone(model)\n",
        "        est.fit(\n",
        "            X_tr, y_tr,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False\n",
        "        )\n",
        "        best_iter = getattr(est, \"best_iteration\", None)\n",
        "        if best_iter is not None:\n",
        "            try:\n",
        "                y_hat = est.predict(X_val, iteration_range=(0, best_iter + 1))\n",
        "            except TypeError:\n",
        "                # Compat old xgboost\n",
        "                y_hat = est.predict(X_val, ntree_limit=getattr(est, \"best_ntree_limit\", 0))\n",
        "        else:\n",
        "            y_hat = est.predict(X_val)\n",
        "        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\n",
        "    return np.array(rmses)\n",
        "\n",
        "cv_rmse_per_fold = cv_rmse(base_xgb, X_train, y_train, tscv)\n",
        "print(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\n",
        "print(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\n",
        "\n",
        "# === 5) Entraînement final + early stopping (val interne 20%)\n",
        "val_cut = max(int(len(X_train) * 0.8), 1)\n",
        "X_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\n",
        "X_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\n",
        "\n",
        "final_xgb = clone(base_xgb)\n",
        "final_xgb.fit(\n",
        "    X_tr, y_tr,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "best_iter = getattr(final_xgb, \"best_iteration\", None)\n",
        "print(\"🏁 Best iteration (ES):\", best_iter)\n",
        "\n",
        "# === 6) Évaluation test ===\n",
        "if best_iter is not None:\n",
        "    try:\n",
        "        y_pred = final_xgb.predict(X_test, iteration_range=(0, best_iter + 1))\n",
        "    except TypeError:\n",
        "        y_pred = final_xgb.predict(X_test, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))\n",
        "else:\n",
        "    y_pred = final_xgb.predict(X_test)\n",
        "\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "\n",
        "print(\"🔎 Évaluation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# === 7) Sauvegarde ===\n",
        "joblib.dump(final_xgb, f\"xgb_iqa_best_{151726}.pkl\")\n",
        "print(f\"✅ Modèle sauvegardé : xgb_iqa_best_{151726}.pkl\")\n",
        "\n",
        "# === 8) Prédiction J+1 ===\n",
        "last_feats = df_lags.drop(columns=['iqa']).iloc[-1:].copy()\n",
        "if best_iter is not None:\n",
        "    try:\n",
        "        pred_next_day = float(final_xgb.predict(last_feats, iteration_range=(0, best_iter + 1))[0])\n",
        "    except TypeError:\n",
        "        pred_next_day = float(final_xgb.predict(last_feats, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))[0])\n",
        "else:\n",
        "    pred_next_day = float(final_xgb.predict(last_feats)[0])\n",
        "print(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\n",
        "\n",
        "# === 9) Prédictions J+1 → J+5 (auto-régression) ===\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "lag_cols = [f'lag_{k}' for k in range(1, n_lags + 1)]\n",
        "step_feats = last_feats.copy()\n",
        "\n",
        "for _ in range(n_days):\n",
        "    if best_iter is not None:\n",
        "        try:\n",
        "            y_hat = float(final_xgb.predict(step_feats, iteration_range=(0, best_iter + 1))[0])\n",
        "        except TypeError:\n",
        "            y_hat = float(final_xgb.predict(step_feats, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))[0])\n",
        "    else:\n",
        "        y_hat = float(final_xgb.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\n",
        "    shifted[0] = y_hat\n",
        "    step_feats[lag_cols] = shifted\n",
        "\n",
        "print(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gAvXR01_kOv3",
        "outputId": "a92804d7-e9d0-46e1-9490-8d9f178a014b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# CECI EST UN TEST D\\'UTILISATION DU MODELE XGB\\n\\n\\n# XGBoost — time-series friendly (lags, TSCV, eval with early stopping, save, multi-step forecast)\\nimport pandas as pd\\nimport numpy as np\\nfrom xgboost import XGBRegressor\\nfrom sklearn.model_selection import TimeSeriesSplit\\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\\nfrom sklearn.base import clone\\nimport joblib\\n\\n# === 1) Données ===\\ndf = df_151726.copy()\\ndf[\\'date\\'] = pd.to_datetime(df[\\'date\\'])\\ndf = df.sort_values(\\'date\\').set_index(\\'date\\').asfreq(\\'D\\')\\ndf[\\'iqa\\'] = df[\\'iqa\\'].interpolate()\\n\\n# === 2) Lags ===\\ndef create_lags(data: pd.DataFrame, n_lags: int) -> pd.DataFrame:\\n    out = data.copy()\\n    for lag in range(1, n_lags + 1):\\n        out[f\\'lag_{lag}\\'] = out[\\'iqa\\'].shift(lag)\\n    return out\\n\\nn_lags = 7\\ndf_lags = create_lags(df[[\\'iqa\\']], n_lags).dropna()\\n\\n# === 3) Split train/test ===\\ntrain_size = int(len(df_lags) * 0.8)\\ntrain = df_lags.iloc[:train_size].copy()\\ntest  = df_lags.iloc[train_size:].copy()\\n\\nX_train, y_train = train.drop(columns=[\\'iqa\\']), train[\\'iqa\\']\\nX_test,  y_test  = test.drop(columns=[\\'iqa\\']),  test[\\'iqa\\']\\n\\n# === 4) CV temporelle (RMSE par fold) — avec early stopping\\nn_splits = max(2, min(5, len(X_train) - 1))\\ntscv = TimeSeriesSplit(n_splits=n_splits)\\n\\nbase_xgb = XGBRegressor(\\n    n_estimators=2000,\\n    learning_rate=0.03,\\n    max_depth=3,\\n    subsample=0.9,\\n    colsample_bytree=0.9,\\n    reg_alpha=0.1,\\n    reg_lambda=1.0,\\n    random_state=42,\\n    n_jobs=-1,\\n    tree_method=\"hist\",\\n    objective=\"reg:squarederror\",\\n    eval_metric=\"rmse\",\\n)\\n\\ndef cv_rmse(model, X, y, splitter):\\n    rmses = []\\n    for tr_idx, val_idx in splitter.split(X):\\n        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\\n        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\\n        est = clone(model)\\n        est.fit(\\n            X_tr, y_tr,\\n            eval_set=[(X_val, y_val)],\\n            verbose=False\\n        )\\n        best_iter = getattr(est, \"best_iteration\", None)\\n        if best_iter is not None:\\n            try:\\n                y_hat = est.predict(X_val, iteration_range=(0, best_iter + 1))\\n            except TypeError:\\n                # Compat old xgboost\\n                y_hat = est.predict(X_val, ntree_limit=getattr(est, \"best_ntree_limit\", 0))\\n        else:\\n            y_hat = est.predict(X_val)\\n        rmses.append(np.sqrt(mean_squared_error(y_val, y_hat)))\\n    return np.array(rmses)\\n\\ncv_rmse_per_fold = cv_rmse(base_xgb, X_train, y_train, tscv)\\nprint(\"📊 CV RMSE per fold :\", np.round(cv_rmse_per_fold, 4))\\nprint(\"📊 CV RMSE mean     :\", np.round(cv_rmse_per_fold.mean(), 4))\\n\\n# === 5) Entraînement final + early stopping (val interne 20%)\\nval_cut = max(int(len(X_train) * 0.8), 1)\\nX_tr, y_tr = X_train.iloc[:val_cut], y_train.iloc[:val_cut]\\nX_val, y_val = X_train.iloc[val_cut:], y_train.iloc[val_cut:]\\n\\nfinal_xgb = clone(base_xgb)\\nfinal_xgb.fit(\\n    X_tr, y_tr,\\n    eval_set=[(X_val, y_val)],\\n    verbose=False\\n)\\nbest_iter = getattr(final_xgb, \"best_iteration\", None)\\nprint(\"🏁 Best iteration (ES):\", best_iter)\\n\\n# === 6) Évaluation test ===\\nif best_iter is not None:\\n    try:\\n        y_pred = final_xgb.predict(X_test, iteration_range=(0, best_iter + 1))\\n    except TypeError:\\n        y_pred = final_xgb.predict(X_test, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))\\nelse:\\n    y_pred = final_xgb.predict(X_test)\\n\\nrmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\\nmae_test  = float(mean_absolute_error(y_test, y_pred))\\nr2_test   = float(r2_score(y_test, y_pred))\\n\\nprint(\"🔎 Évaluation sur test :\")\\nprint(f\"   RMSE = {rmse_test:.4f}\")\\nprint(f\"   MAE  = {mae_test:.4f}\")\\nprint(f\"   R2   = {r2_test:.4f}\")\\n\\n# === 7) Sauvegarde ===\\njoblib.dump(final_xgb, f\"xgb_iqa_best_{151726}.pkl\")\\nprint(f\"✅ Modèle sauvegardé : xgb_iqa_best_{151726}.pkl\")\\n\\n# === 8) Prédiction J+1 ===\\nlast_feats = df_lags.drop(columns=[\\'iqa\\']).iloc[-1:].copy()\\nif best_iter is not None:\\n    try:\\n        pred_next_day = float(final_xgb.predict(last_feats, iteration_range=(0, best_iter + 1))[0])\\n    except TypeError:\\n        pred_next_day = float(final_xgb.predict(last_feats, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))[0])\\nelse:\\n    pred_next_day = float(final_xgb.predict(last_feats)[0])\\nprint(f\"📅 Prédiction J+1 : {pred_next_day:.2f}\")\\n\\n# === 9) Prédictions J+1 → J+5 (auto-régression) ===\\nn_days = 5\\nmulti_preds = []\\nlag_cols = [f\\'lag_{k}\\' for k in range(1, n_lags + 1)]\\nstep_feats = last_feats.copy()\\n\\nfor _ in range(n_days):\\n    if best_iter is not None:\\n        try:\\n            y_hat = float(final_xgb.predict(step_feats, iteration_range=(0, best_iter + 1))[0])\\n        except TypeError:\\n            y_hat = float(final_xgb.predict(step_feats, ntree_limit=getattr(final_xgb, \"best_ntree_limit\", 0))[0])\\n    else:\\n        y_hat = float(final_xgb.predict(step_feats)[0])\\n    multi_preds.append(y_hat)\\n    shifted = np.roll(step_feats[lag_cols].to_numpy().ravel(), 1)\\n    shifted[0] = y_hat\\n    step_feats[lag_cols] = shifted\\n\\nprint(\"📅 Prédictions J+1 à J+5 :\", [round(p, 2) for p in multi_preds])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwuTzUgOIs3X"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}