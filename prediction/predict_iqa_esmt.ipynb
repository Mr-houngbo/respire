{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR7vp0ebSLAh3/vXTMYZUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mr-houngbo/respire/blob/main/prediction/predict_iqa_esmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teR3-EJiwJbX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KWcctNSAwTHH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "import gdown\n",
        "\n",
        "# ID des Datasets et noms des outputs\n",
        "file_ids = [\"1BZazndHP417b_nUGeSxmB-wdaYDb6Ngk\"]\n",
        "outputs = [\"iqa-164928.csv\"]\n",
        "\n",
        "\n",
        "for i,file_id in enumerate(file_ids):\n",
        "  url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "  output = outputs[i]\n",
        "  gdown.download(url, output, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3K2YF-swTDo",
        "outputId": "2a63853d-6f15-4125-a533-6f8e7df5a0b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BZazndHP417b_nUGeSxmB-wdaYDb6Ngk\n",
            "To: /content/iqa-164928.csv\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 427/427 [00:00<00:00, 620kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "import gdown\n",
        "\n",
        "lien = \"https://drive.google.com/file/d//view?usp=sharing\"\n",
        "\n",
        "\n",
        "# ID du Dataset\n",
        "file_id = \"1b4sKColUCmG2LhQO54tRA2_okXiTvR8I\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "output = \"164928.csv\"\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Rfu3SBF1we3x",
        "outputId": "70148a2e-6b00-4c95-9952-25b675fad4bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1b4sKColUCmG2LhQO54tRA2_okXiTvR8I\n",
            "To: /content/164928.csv\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.62k/3.62k [00:00<00:00, 3.84MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'164928.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_iqa_164928 = pd.read_csv(\"iqa-164928.csv\")\n",
        "esmt = pd.read_csv(\"164928.csv\")"
      ],
      "metadata": {
        "id": "JrdPgZjpwTB0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n2xpHoSbwZP5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Harmoniser : enlever timezone\n",
        "esmt['UTC Date/Time'] = pd.to_datetime(esmt['UTC Date/Time']).dt.tz_localize(None)\n",
        "df_iqa_164928['date'] = pd.to_datetime(df_iqa_164928['date'])\n",
        "\n",
        "# Merge\n",
        "merged = pd.merge(\n",
        "    esmt,\n",
        "    df_iqa_164928,\n",
        "    left_on='UTC Date/Time',\n",
        "    right_on='date',\n",
        "    how='inner'\n",
        ").drop(columns=['date'])\n",
        "\n",
        "print(merged.info())\n",
        "print(merged.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaA4saBAwZMj",
        "outputId": "9a870a51-ab59-4b7e-ec44-a5dd5a12bc40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18 entries, 0 to 17\n",
            "Data columns (total 25 columns):\n",
            " #   Column                      Non-Null Count  Dtype         \n",
            "---  ------                      --------------  -----         \n",
            " 0   Location ID                 18 non-null     int64         \n",
            " 1   Location Name               18 non-null     object        \n",
            " 2   Location Group              0 non-null      float64       \n",
            " 3   Location Type               18 non-null     object        \n",
            " 4   Sensor ID                   18 non-null     object        \n",
            " 5   Place Open                  18 non-null     bool          \n",
            " 6   Local Date/Time             18 non-null     object        \n",
            " 7   UTC Date/Time               18 non-null     datetime64[ns]\n",
            " 8   # of aggregated records     18 non-null     int64         \n",
            " 9   PM2.5 (Î¼g/mÂ³) raw           18 non-null     float64       \n",
            " 10  PM2.5 (Î¼g/mÂ³) corrected     18 non-null     float64       \n",
            " 11  0.3Î¼m particle count        18 non-null     int64         \n",
            " 12  CO2 (ppm) raw               18 non-null     int64         \n",
            " 13  CO2 (ppm) corrected         18 non-null     int64         \n",
            " 14  Temperature (Â°C) raw        18 non-null     float64       \n",
            " 15  Temperature (Â°C) corrected  18 non-null     float64       \n",
            " 16  Heat Index (Â°C)             18 non-null     float64       \n",
            " 17  Humidity (%) raw            18 non-null     int64         \n",
            " 18  Humidity (%) corrected      18 non-null     int64         \n",
            " 19  TVOC (ppb)                  18 non-null     int64         \n",
            " 20  TVOC index                  18 non-null     int64         \n",
            " 21  NOX index                   18 non-null     int64         \n",
            " 22  PM1 (Î¼g/mÂ³)                 18 non-null     float64       \n",
            " 23  PM10 (Î¼g/mÂ³)                18 non-null     float64       \n",
            " 24  iqa                         18 non-null     float64       \n",
            "dtypes: bool(1), datetime64[ns](1), float64(9), int64(10), object(4)\n",
            "memory usage: 3.5+ KB\n",
            "None\n",
            "   Location ID Location Name  Location Group Location Type  \\\n",
            "0       164928   Breath4life             NaN       Outdoor   \n",
            "1       164928   Breath4life             NaN       Outdoor   \n",
            "2       164928   Breath4life             NaN       Outdoor   \n",
            "3       164928   Breath4life             NaN       Outdoor   \n",
            "4       164928   Breath4life             NaN       Outdoor   \n",
            "\n",
            "                  Sensor ID  Place Open      Local Date/Time UTC Date/Time  \\\n",
            "0  airgradient:d83bda1d43d8        True  2025-08-08 00:00:00    2025-08-08   \n",
            "1  airgradient:d83bda1d43d8        True  2025-08-07 00:00:00    2025-08-07   \n",
            "2  airgradient:d83bda1d43d8        True  2025-08-06 00:00:00    2025-08-06   \n",
            "3  airgradient:d83bda1d43d8        True  2025-08-05 00:00:00    2025-08-05   \n",
            "4  airgradient:d83bda1d43d8        True  2025-08-04 00:00:00    2025-08-04   \n",
            "\n",
            "   # of aggregated records  PM2.5 (Î¼g/mÂ³) raw  ...  \\\n",
            "0                     1173               15.4  ...   \n",
            "1                     1315                7.9  ...   \n",
            "2                     1348                8.3  ...   \n",
            "3                     1312               14.2  ...   \n",
            "4                     1252               13.5  ...   \n",
            "\n",
            "   Temperature (Â°C) corrected  Heat Index (Â°C)  Humidity (%) raw  \\\n",
            "0                        30.2             37.6                56   \n",
            "1                        30.6             38.9                57   \n",
            "2                        31.5             40.7                54   \n",
            "3                        30.1             37.5                56   \n",
            "4                        30.6             37.5                53   \n",
            "\n",
            "   Humidity (%) corrected  TVOC (ppb)  TVOC index  NOX index  PM1 (Î¼g/mÂ³)  \\\n",
            "0                      78         123         120          1          5.6   \n",
            "1                      79          89          91          1          2.7   \n",
            "2                      76         121         115          1          3.7   \n",
            "3                      78         133         123          1          6.1   \n",
            "4                      74         143         135          1          6.0   \n",
            "\n",
            "   PM10 (Î¼g/mÂ³)     iqa  \n",
            "0          18.1  133.08  \n",
            "1           9.4  131.17  \n",
            "2           9.3  126.31  \n",
            "3          16.2  130.71  \n",
            "4          15.2  122.53  \n",
            "\n",
            "[5 rows x 25 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer colonnes inutiles\n",
        "cols_a_supprimer = [\n",
        "    'Location ID', 'Location Name', 'Location Group', 'Location Type',\n",
        "    'Sensor ID', 'Place Open', 'UTC Date/Time','# of aggregated records'] + [col for col in merged.columns if \"raw\" in col.lower()]  # remove raw\n",
        "\n",
        "merged.drop(columns=cols_a_supprimer, inplace=True, errors='ignore')"
      ],
      "metadata": {
        "id": "pEgg9ia1xPeh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJri-h_AxPa4",
        "outputId": "d6ee1483-a68a-433b-8121-a6eff4b6a2d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18 entries, 0 to 17\n",
            "Data columns (total 13 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   Local Date/Time             18 non-null     object \n",
            " 1   PM2.5 (Î¼g/mÂ³) corrected     18 non-null     float64\n",
            " 2   0.3Î¼m particle count        18 non-null     int64  \n",
            " 3   CO2 (ppm) corrected         18 non-null     int64  \n",
            " 4   Temperature (Â°C) corrected  18 non-null     float64\n",
            " 5   Heat Index (Â°C)             18 non-null     float64\n",
            " 6   Humidity (%) corrected      18 non-null     int64  \n",
            " 7   TVOC (ppb)                  18 non-null     int64  \n",
            " 8   TVOC index                  18 non-null     int64  \n",
            " 9   NOX index                   18 non-null     int64  \n",
            " 10  PM1 (Î¼g/mÂ³)                 18 non-null     float64\n",
            " 11  PM10 (Î¼g/mÂ³)                18 non-null     float64\n",
            " 12  iqa                         18 non-null     float64\n",
            "dtypes: float64(6), int64(6), object(1)\n",
            "memory usage: 2.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Mi8bA-RxPYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictionnnn"
      ],
      "metadata": {
        "id": "_zKc40V80XBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PrÃ©diction IQA J+1 avec XGBoost en utilisant TOUTES les features disponibles\n",
        "# HypothÃ¨se pour la prÃ©vision J+1â†’J+5 : les variables exogÃ¨nes (PM, CO2, etc.)\n",
        "# suivent une persistance (valeur du dernier jour connue). On entraÃ®ne sur des lags.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.base import clone\n",
        "import joblib\n",
        "\n",
        "# ========= 1) PrÃ©paration =========\n",
        "# df_raw : DataFrame que tu viens dâ€™afficher (13 colonnes)\n",
        "df_raw = merged.copy()  # mets ici ton DataFrame (celui avec 'Local Date/Time' et toutes les mesures)\n",
        "\n",
        "# Passer la date en datetime et trier\n",
        "df_raw['Local Date/Time'] = pd.to_datetime(df_raw['Local Date/Time'])\n",
        "df_raw = df_raw.sort_values('Local Date/Time').reset_index(drop=True)\n",
        "\n",
        "# (Optionnel) forcer un pas journalier et combler s'il manque des jours\n",
        "df_raw = df_raw.set_index('Local Date/Time').asfreq('D')\n",
        "# Interpolation simple pour combler dâ€™Ã©ventuels trous\n",
        "for c in df_raw.columns:\n",
        "    df_raw[c] = df_raw[c].interpolate()\n",
        "\n",
        "df_raw = df_raw.reset_index().rename(columns={'Local Date/Time': 'date'})\n",
        "\n",
        "# ========= 2) Lags =========\n",
        "# On crÃ©e des lags pour TOUTES les features exogÃ¨nes + plusieurs lags pour la cible\n",
        "target_col = 'iqa'\n",
        "exog_cols = [c for c in df_raw.columns if c not in ['date', target_col]]\n",
        "\n",
        "# ParamÃ¨tres de lags\n",
        "n_lags_target = 1   # lags pour iqa\n",
        "n_lags_exog   = 1   # lags pour les exogÃ¨nes\n",
        "\n",
        "def make_lags(df_in: pd.DataFrame, target: str, exog: list, n_t: int, n_x: int) -> pd.DataFrame:\n",
        "    df_out = df_in.copy()\n",
        "    # lags de la cible\n",
        "    for k in range(1, n_t + 1):\n",
        "        df_out[f'{target}_lag_{k}'] = df_out[target].shift(k)\n",
        "    # lags des exogÃ¨nes\n",
        "    for col in exog:\n",
        "        for k in range(1, n_x + 1):\n",
        "            df_out[f'{col}_lag_{k}'] = df_out[col].shift(k)\n",
        "    return df_out\n",
        "\n",
        "df_lags = make_lags(df_raw, target_col, exog_cols, n_lags_target, n_lags_exog).dropna().reset_index(drop=True)\n",
        "\n",
        "# ========= 3) Train / Test =========\n",
        "# On prÃ©dit iqa (courant) Ã  partir des lags (donc J est prÃ©dit par J-1, J-2, ...)\n",
        "features = [c for c in df_lags.columns if c not in ['date', target_col]]\n",
        "X = df_lags[features]\n",
        "y = df_lags[target_col]\n",
        "\n",
        "train_size = int(len(df_lags) * 0.8)\n",
        "X_train, y_train = X.iloc[:train_size], y.iloc[:train_size]\n",
        "X_test,  y_test  = X.iloc[train_size:], y.iloc[train_size:]\n",
        "\n",
        "# ========= 4) CV + EntraÃ®nement =========\n",
        "n_splits = max(2, min(5, len(X_train) - 1))\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "base_xgb = XGBRegressor(\n",
        "    n_estimators=800,\n",
        "    learning_rate=0.04,\n",
        "    max_depth=3,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric=\"rmse\",  # compatible v2+ (dÃ©fini dans le constructeur)\n",
        ")\n",
        "\n",
        "# CV manuelle (pas d'early_stopping pour compat toutes versions)\n",
        "cv_rmses = []\n",
        "for tr_idx, val_idx in tscv.split(X_train):\n",
        "    est = clone(base_xgb)\n",
        "    est.fit(X_train.iloc[tr_idx], y_train.iloc[tr_idx], verbose=False)\n",
        "    y_val_hat = est.predict(X_train.iloc[val_idx])\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_train.iloc[val_idx], y_val_hat)))\n",
        "    cv_rmses.append(rmse)\n",
        "\n",
        "cv_rmses = np.array(cv_rmses)\n",
        "print(\"ðŸ“Š CV RMSE per fold :\", np.round(cv_rmses, 4))\n",
        "print(\"ðŸ“Š CV RMSE mean     :\", np.round(cv_rmses.mean(), 4))\n",
        "\n",
        "# EntraÃ®nement final sur tout le train\n",
        "final_xgb = clone(base_xgb)\n",
        "final_xgb.fit(X_train, y_train, verbose=False)\n",
        "\n",
        "# ========= 5) Ã‰valuation =========\n",
        "y_pred = final_xgb.predict(X_test)\n",
        "rmse_test = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "mae_test  = float(mean_absolute_error(y_test, y_pred))\n",
        "r2_test   = float(r2_score(y_test, y_pred))\n",
        "print(\"ðŸ”Ž Ã‰valuation sur test :\")\n",
        "print(f\"   RMSE = {rmse_test:.4f}\")\n",
        "print(f\"   MAE  = {mae_test:.4f}\")\n",
        "print(f\"   R2   = {r2_test:.4f}\")\n",
        "\n",
        "# ========= 6) Sauvegarde =========\n",
        "joblib.dump(final_xgb, \"xgb_iqa_all_features.pkl\")\n",
        "print(\"âœ… ModÃ¨le sauvegardÃ© : xgb_iqa_all_features.pkl\")\n",
        "\n",
        "# ========= 7) PrÃ©vision J+1 =========\n",
        "# On part de la derniÃ¨re ligne connue et de ses lags dÃ©jÃ  construits\n",
        "last_row = X.iloc[[-1]]  # DataFrame 1xN\n",
        "pred_j1 = float(final_xgb.predict(last_row)[0])\n",
        "print(f\"ðŸ“… PrÃ©diction J+1 : {pred_j1:.2f}\")\n",
        "\n",
        "# ========= 8) PrÃ©visions J+1 â†’ J+5 (auto-rÃ©gression) =========\n",
        "# RÃ¨gle de persistance pour les exogÃ¨nes : leurs lags avancent en gardant la derniÃ¨re valeur connue.\n",
        "# Les lags de iqa se mettent Ã  jour avec les prÃ©dictions successives.\n",
        "\n",
        "n_days = 5\n",
        "multi_preds = []\n",
        "\n",
        "# On travaille sur une copie des features de la derniÃ¨re ligne\n",
        "step_feats = last_row.copy()\n",
        "\n",
        "# Colonnes de lags cible et exogÃ¨nes\n",
        "iqa_lag_cols = [f'{target_col}_lag_{k}' for k in range(1, n_lags_target + 1)]\n",
        "exog_lag_cols = []\n",
        "for col in exog_cols:\n",
        "    for k in range(1, n_lags_exog + 1):\n",
        "        exog_lag_cols.append(f'{col}_lag_{k}')\n",
        "\n",
        "for _ in range(n_days):\n",
        "    # prÃ©dire\n",
        "    y_hat = float(final_xgb.predict(step_feats)[0])\n",
        "    multi_preds.append(y_hat)\n",
        "\n",
        "    # 1) MAJ lags iqa : shift Ã  droite et mettre lag_1 = y_hat\n",
        "    iqa_vals = step_feats[iqa_lag_cols].to_numpy().ravel()\n",
        "    iqa_vals = np.roll(iqa_vals, 1)\n",
        "    iqa_vals[0] = y_hat\n",
        "    step_feats[iqa_lag_cols] = iqa_vals\n",
        "\n",
        "    # 2) MAJ lags exogÃ¨nes : persistance (on rÃ©pÃ¨te la derniÃ¨re valeur)\n",
        "    if len(exog_lag_cols) > 0:\n",
        "        exog_vals = step_feats[exog_lag_cols].to_numpy().ravel()\n",
        "        exog_vals = np.roll(exog_vals, 1)\n",
        "        # pour persistance, on remet exog_lag_1 = exog_lag_1 actuel (avant shift) â†’ on rÃ©cupÃ¨re l'ancienne valeur\n",
        "        # Ici, plus simple : on garde la valeur aprÃ¨s shift (Ã©quivaut Ã  persistance de la derniÃ¨re connue)\n",
        "        step_feats[exog_lag_cols] = exog_vals\n",
        "\n",
        "print(\"ðŸ“… PrÃ©dictions J+1 Ã  J+5 :\", [round(p, 2) for p in multi_preds])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKhbtao0wz-i",
        "outputId": "ff7466b8-eea3-46fc-f529-3dc7cfc85756"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š CV RMSE per fold : [9.8528 3.171  4.2602 3.4989 1.3899]\n",
            "ðŸ“Š CV RMSE mean     : 4.4346\n",
            "ðŸ”Ž Ã‰valuation sur test :\n",
            "   RMSE = 1.4155\n",
            "   MAE  = 0.9035\n",
            "   R2   = 0.8629\n",
            "âœ… ModÃ¨le sauvegardÃ© : xgb_iqa_all_features.pkl\n",
            "ðŸ“… PrÃ©diction J+1 : 130.04\n",
            "ðŸ“… PrÃ©dictions J+1 Ã  J+5 : [130.04, 129.66, 130.02, 129.55, 128.94]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYbVC6GGzTHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQMW0xO9zTDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7XBEoFQzTBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}