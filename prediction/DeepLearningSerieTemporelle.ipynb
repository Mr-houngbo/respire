{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JImu_vBTK_p7"
      },
      "source": [
        "\n",
        "# **TP : Prévision d’une série temporelle avec Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv61aNV1Vtzm"
      },
      "source": [
        "\n",
        "\n",
        "1.   Élément de liste\n",
        "2.   Élément de liste\n",
        "\n",
        "\n",
        "\n",
        "*   L'ensemble de données climatiques de Jena est composé de 14 variables différentes (telles que la température de l'air, la pression atmosphérique, l'humidité, la direction du vent,\n",
        "etc.) qui ont été enregistrées toutes les 10 minutes, sur plusieurs années.\n",
        "*   Ce jeu de données couvre la période du 1er janvier 2009 au 31 décembre 2016. ( disponible sur ce lien https://www.kaggle.com/datasets/mnassrib/jena-climate)\n",
        "*  \n",
        "Notre objectif est de prédire la série temporelle de la température (colonne intitulée T (degC)) en utilisant uniquement cette variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4lu-q2SLpwW"
      },
      "source": [
        "## Importation des bibliothèques\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu3fOFYwNDPW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLtP6hCcRwAV"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pwpMOfoxGXz"
      },
      "source": [
        "## Téléchargement de la base de données\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "FatV705zMbFK",
        "outputId": "ebafa509-fe22-4ec6-e2eb-94665dac1d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'/content/drive/MyDrive/Proj.csv')"
      ],
      "metadata": {
        "id": "exRqJ3ylNmeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6vhMtApxGX0"
      },
      "source": [
        "# Traitement et Extraction des Données du Fichier Climatique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHQ8V42ANeaQ"
      },
      "outputs": [],
      "source": [
        "# Extraction de la colonne \"Date Time\" pour les dates\n",
        "dates = data[\"Date Time\"]\n",
        "\n",
        "# Extraction de la colonne \"T (degC)\" (température)\n",
        "temperature = data[\"T (degC)\"]\n",
        "\n",
        "# Conversion des données restantes en un tableau (sans \"Date Time\")\n",
        "raw_data = data.drop(columns=[\"Date Time\"]).to_numpy()\n",
        "\n",
        "# Affichage des premières lignes pour vérifier\n",
        "#print(\"Premières dates :\", dates.head().tolist())\n",
        "#print(\"Premières températures :\", temperature.head().tolist())\n",
        "#print(\"Extrait des données brutes :\", raw_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGWkCeOLxGX1"
      },
      "outputs": [],
      "source": [
        "# Tracer la température en fonction du temps\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(dates, temperature, label='Température (°C)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Température (°C)')\n",
        "plt.title('Température en fonction du temps')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nJu0pj7xGX1"
      },
      "source": [
        "# Séparation des données en ensembles d'entraînement, de validation et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlBB7GEgxGX1"
      },
      "outputs": [],
      "source": [
        "# Séparation des données en ensembles d'entraînement, de validation et de test\n",
        "\n",
        "# Calcul du nombre d'échantillons pour chaque ensemble\n",
        "num_train_samples = int(0.7 * len(raw_data))  # 70% des données pour l'entraînement\n",
        "num_val_samples = int(0.15 * len(raw_data))   # 15% des données pour la validation\n",
        "num_test_samples = len(raw_data) - num_train_samples - num_val_samples  # Le reste pour le test\n",
        "\n",
        "# Affichage du nombre d'échantillons dans chaque ensemble\n",
        "print(\"num_train_samples:\", num_train_samples)\n",
        "print(\"num_val_samples:\", num_val_samples)\n",
        "print(\"num_test_samples:\", num_test_samples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSD9oQwTxGX1"
      },
      "source": [
        "### Preparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ9MEaTgxGX1"
      },
      "outputs": [],
      "source": [
        "# Normalisation des Données\n",
        "# Calcul de la moyenne des données d'entraînement\n",
        "mean = raw_data[:num_train_samples].mean(axis=0)\n",
        "\n",
        "# Soustraction de la moyenne à l'ensemble des données pour centrer les données\n",
        "raw_data -= mean\n",
        "\n",
        "# Calcul de l'écart type des données d'entraînement\n",
        "std = raw_data[:num_train_samples].std(axis=0)\n",
        "\n",
        "# Division par l'écart type pour normaliser les données\n",
        "raw_data /= std\n",
        "#print(raw_data[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcNVKUVexGX1"
      },
      "outputs": [],
      "source": [
        "# Création des Jeux de Données de Séries Temporelles pour l'Entraînement, la Validation et le Test\n",
        "\n",
        "# Paramètres pour la création des séries temporelles\n",
        "sampling_rate = 6  # Taux d'échantillonnage\n",
        "sequence_length = 120  # Longueur de chaque séquence\n",
        "delay = sampling_rate * (sequence_length + 24 - 1)  # Délai pour aligner les cibles\n",
        "batch_size = 256  # Taille de chaque batch\n",
        "\n",
        "# Création du jeu de données d'entraînement\n",
        "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    data=raw_data[:-delay],  # Données d'entrée (tout sauf les derniers 'delay' éléments)\n",
        "    targets=temperature[delay:],  # Cibles (décalées de 'delay' éléments)\n",
        "    sampling_rate=sampling_rate,  # Taux d'échantillonnage\n",
        "    sequence_length=sequence_length,  # Longueur de chaque séquence\n",
        "    shuffle=True,  # Mélanger les données pour l'entraînement\n",
        "    batch_size=batch_size,  # Taille de chaque batch\n",
        "    start_index=0,  # Index de début des données d'entraînement\n",
        "    end_index=num_train_samples  # Index de fin des données d'entraînement\n",
        ")\n",
        "\n",
        "# Création du jeu de données de validation\n",
        "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    data=raw_data[:-delay],  # Données d'entrée (tout sauf les derniers 'delay' éléments)\n",
        "    targets=temperature[delay:],  # Cibles (décalées de 'delay' éléments)\n",
        "    sampling_rate=sampling_rate,  # Taux d'échantillonnage\n",
        "    sequence_length=sequence_length,  # Longueur de chaque séquence\n",
        "    shuffle=True,  # Mélanger les données pour la validation\n",
        "    batch_size=batch_size,  # Taille de chaque batch\n",
        "    start_index=num_train_samples,  # Index de début des données de validation\n",
        "    end_index=num_train_samples + num_val_samples  # Index de fin des données de validation\n",
        ")\n",
        "\n",
        "# Création du jeu de données de test\n",
        "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
        "    data=raw_data[:-delay],  # Données d'entrée (tout sauf les derniers 'delay' éléments)\n",
        "    targets=temperature[delay:],  # Cibles (décalées de 'delay' éléments)\n",
        "    sampling_rate=sampling_rate,  # Taux d'échantillonnage\n",
        "    sequence_length=sequence_length,  # Longueur de chaque séquence\n",
        "    shuffle=True,  # Mélanger les données pour le test\n",
        "    batch_size=batch_size,  # Taille de chaque batch\n",
        "    start_index=num_train_samples + num_val_samples  # Index de début des données de test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7M-ZuLNxGX1"
      },
      "source": [
        "# Création des Jeux de Données de Séries Temporelles pour l'Entraînement, la Validation et le Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghYmCVpWxGX2"
      },
      "source": [
        "**Inspecting the output of one of our datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8qk8I7wxGX2"
      },
      "outputs": [],
      "source": [
        "# Vérification de la Forme des Échantillons et des Cibles dans le Jeu de Données d'Entraînement\n",
        "\n",
        "# Boucle pour itérer sur le jeu de données d'entraînement\n",
        "for samples, targets in train_dataset:\n",
        "    # Afficher la forme des échantillons\n",
        "    print(\"samples shape:\", samples.shape)\n",
        "\n",
        "    # Afficher la forme des cibles\n",
        "    print(\"targets shape:\", targets.shape)\n",
        "\n",
        "    # Sortir de la boucle après la première itération\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnsyWKL0dPOr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xipbfj3ZDsN6"
      },
      "source": [
        "# Modèle LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9ms-COaZjTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDSZx_ZAkcM0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5jZ0NcGD9Lw"
      },
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YG-uk0DoeJ8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uILD2DTDECyv"
      },
      "outputs": [],
      "source": [
        "# Afficher le résumé du modèle\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i576_s0vDiWg"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cli8HwBQxGX2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Entraîner le modèle sur les données d'entraînement\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,  # Vous pouvez ajuster le nombre d'époques en fonction de vos besoins\n",
        "    validation_data=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjNfOgLfEPmo",
        "outputId": "70371c10-0aa4-4180-8e97-90655feabee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-631946641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Évaluer le modèle sur les données de validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation Loss: {val_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# (Optionnel) Évaluer le modèle sur les données de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Évaluer le modèle sur les données de validation\n",
        "val_loss = model.evaluate(val_dataset)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "# (Optionnel) Évaluer le modèle sur les données de test\n",
        "test_loss = model.evaluate(test_dataset)\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVo0y6g9ERED"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Faire des prédictions sur les données de test\n",
        "test_predictions = model.predict(test_dataset)\n",
        "\n",
        "# Extraire les cibles réelles des données de test\n",
        "test_targets = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "# Inverser la normalisation pour obtenir les valeurs réelles\n",
        "test_predictions = test_predictions * std[1] + mean[1]\n",
        "test_targets = test_targets * std[1] + mean[1]\n",
        "\n",
        "# Tracer les valeurs réelles et prédites\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(test_targets[:30], label='Valeurs Réelles')\n",
        "plt.plot(test_predictions[:30], label='Valeurs Prédites')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Température (°C)')\n",
        "plt.title('Valeurs Réelles vs. Valeurs Prédites (30 premières valeurs)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G874UR1RH7KG"
      },
      "outputs": [],
      "source": [
        "# Prédiction de la température sur les 30 prochains jours\n",
        "# Pour cela, nous utilisons la dernière séquence de test pour prédire les 30 prochains jours\n",
        "last_sequence = raw_data[-sequence_length:]  # Dernière séquence\n",
        "predictions_30_days = []\n",
        "\n",
        "for _ in range(30):\n",
        "    # Ajouter une nouvelle dimension pour correspondre à l'entrée attendue du modèle\n",
        "    input_sequence = last_sequence[np.newaxis, ...]\n",
        "\n",
        "    # Prédire la température\n",
        "    prediction = model.predict(input_sequence)[0][0]\n",
        "\n",
        "    # Inverser la normalisation pour obtenir la valeur réelle\n",
        "    prediction = prediction * std[1] + mean[1]\n",
        "    predictions_30_days.append(prediction)\n",
        "\n",
        "    # Ajouter la nouvelle prédiction à la séquence et enlever la plus ancienne\n",
        "    new_value = (prediction - mean[1]) / std[1]  # Normaliser la nouvelle prédiction\n",
        "    last_sequence = np.roll(last_sequence, -1, axis=0)  # Décaler la séquence\n",
        "    last_sequence[-1, 1] = new_value  # Mettre à jour avec la nouvelle prédiction\n",
        "\n",
        "# Afficher les prédictions pour les 30 prochains jours\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(predictions_30_days, label='Prédictions pour les 30 prochains jours')\n",
        "plt.xlabel('Jour')\n",
        "plt.ylabel('Température (°C)')\n",
        "plt.title('Prédictions de Température pour les 30 Prochains Jours')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x79NxBrMBwq_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF--qz5CcYQK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
